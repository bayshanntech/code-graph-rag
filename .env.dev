# Gemini settings
#GEMINI_API_KEY=your-gemini-api-key
#GEMINI_MODEL_ID=gemini-2.5-pro-preview-06-05
#MODEL_CYPHER_ID=gemini-2.5-flash-lite-preview-06-17

# Option 4
ANTHROPIC_API_KEY=anthropic-key
ANTHROPIC_ORCHESTRATOR_MODEL_ID="claude-3-5-sonnet-latest"
ANTHROPIC_CYPHER_MODEL_ID="claude-3-5-sonnet-latest"

# Option 2
OPENAI_API_KEY=open-api-key
OPENAI_ORCHESTRATOR_MODEL_ID="gpt-5"
OPENAI_CYPHER_MODEL_ID="gpt-5"

# Local model settings
# Example for Ollama:
#LOCAL_MODEL_ENDPOINT="http://localhost:11434/v1"
#LOCAL_ORCHESTRATOR_MODEL_ID="llama3"
#LOCAL_CYPHER_MODEL_ID="llama3"
#LOCAL_MODEL_API_KEY="ollama" # Ollama uses "ollama" as a placeholder

MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
LAB_PORT=3000
TARGET_REPO_PATH=.
